{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "To avoid features being derived from other features split the data into subsets *mean_* and *percent_* features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/processed/raw.csv\")\n",
    "df.drop([\"school\", \"q1\", \"q3\", \"grade\"], axis=1, inplace=True)\n",
    "X = df.drop([\"name\", \"event\", \"place\", \"all_american\", \"score\"], axis=1)\n",
    "X[\"year\"] /= 4\n",
    "\n",
    "y_score = df[\"score\"]\n",
    "y_all_am = df[\"all_american\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare scaled data for later\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "columns = list(X.columns[:-1]) # Year scaling is dividing by 4\n",
    "X_scaled_np = scaler.fit_transform(X.drop([\"year\"], axis=1))\n",
    "X_scaled = pd.DataFrame(X_scaled_np, columns=columns)\n",
    "X_scaled = pd.concat([df[[\"all_american\", \"score\"]], X_scaled, df[\"year\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means = df.drop([\"name\", \"place\", \"percent_diff_recent_best\", \"percent_diff_recent_worst\"], axis=1)\n",
    "df_means.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>all_american</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>percent_diff_recent_best</th>\n",
       "      <th>percent_diff_recent_worst</th>\n",
       "      <th>no_mark_rate</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939713</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.966135</td>\n",
       "      <td>0.011727</td>\n",
       "      <td>0.966536</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964637</td>\n",
       "      <td>1.003064</td>\n",
       "      <td>0.974430</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.971316</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event  all_american       min       max      mean       std    median  \\\n",
       "0   100             1  0.939713  0.982000  0.966135  0.011727  0.966536   \n",
       "1   100             1  0.964637  1.003064  0.974430  0.011425  0.971316   \n",
       "\n",
       "   percent_diff_recent_best  percent_diff_recent_worst  no_mark_rate  count  \\\n",
       "0                  0.013292                   0.017410           0.0     16   \n",
       "1                  0.000230                   0.007804           0.0      9   \n",
       "\n",
       "   year     score  \n",
       "0     2  1.000000  \n",
       "1     1  0.958333  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percents = df.drop([\"name\", \"place\", \"mean_three_recent\", \"mean_three_best\", \"mean_three_worst\"], axis=1)\n",
    "df_percents.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "Check if any features are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_american</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>mean_three_recent</th>\n",
       "      <th>mean_three_best</th>\n",
       "      <th>mean_three_worst</th>\n",
       "      <th>percent_diff_recent_best</th>\n",
       "      <th>percent_diff_recent_worst</th>\n",
       "      <th>no_mark_rate</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_american</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746160</td>\n",
       "      <td>0.868393</td>\n",
       "      <td>-0.863812</td>\n",
       "      <td>0.839157</td>\n",
       "      <td>0.868393</td>\n",
       "      <td>0.757867</td>\n",
       "      <td>0.958043</td>\n",
       "      <td>-0.742832</td>\n",
       "      <td>-0.834228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941817</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>0.979613</td>\n",
       "      <td>0.832441</td>\n",
       "      <td>-0.402534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.868393</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.608691</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957523</td>\n",
       "      <td>0.951560</td>\n",
       "      <td>-0.633585</td>\n",
       "      <td>-0.566721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.863812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.608691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565123</td>\n",
       "      <td>-0.608691</td>\n",
       "      <td>-0.427707</td>\n",
       "      <td>-0.791583</td>\n",
       "      <td>0.805915</td>\n",
       "      <td>0.915533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839157</td>\n",
       "      <td>0.941817</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>-0.565123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>0.930132</td>\n",
       "      <td>-0.616570</td>\n",
       "      <td>-0.517846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_three_recent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.868393</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.608691</td>\n",
       "      <td>0.994070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957523</td>\n",
       "      <td>0.951560</td>\n",
       "      <td>-0.633585</td>\n",
       "      <td>-0.566721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_three_best</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757867</td>\n",
       "      <td>0.979613</td>\n",
       "      <td>0.957523</td>\n",
       "      <td>-0.427707</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>0.957523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_three_worst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958043</td>\n",
       "      <td>0.832441</td>\n",
       "      <td>0.951560</td>\n",
       "      <td>-0.791583</td>\n",
       "      <td>0.930132</td>\n",
       "      <td>0.951560</td>\n",
       "      <td>0.841396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.786998</td>\n",
       "      <td>-0.789165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_diff_recent_best</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.742832</td>\n",
       "      <td>-0.402534</td>\n",
       "      <td>-0.633585</td>\n",
       "      <td>0.805915</td>\n",
       "      <td>-0.616570</td>\n",
       "      <td>-0.633585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.786998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_diff_recent_worst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.566721</td>\n",
       "      <td>0.915533</td>\n",
       "      <td>-0.517846</td>\n",
       "      <td>-0.566721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.789165</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_mark_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557427</td>\n",
       "      <td>0.504491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.814729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           all_american       min       max      mean  \\\n",
       "all_american                   1.000000       NaN       NaN       NaN   \n",
       "min                                 NaN  1.000000  0.746160  0.868393   \n",
       "max                                 NaN  0.746160  1.000000  0.945981   \n",
       "mean                                NaN  0.868393  0.945981  1.000000   \n",
       "std                                 NaN -0.863812       NaN -0.608691   \n",
       "median                              NaN  0.839157  0.941817  0.994070   \n",
       "mean_three_recent                   NaN  0.868393  0.945981  1.000000   \n",
       "mean_three_best                     NaN  0.757867  0.979613  0.957523   \n",
       "mean_three_worst                    NaN  0.958043  0.832441  0.951560   \n",
       "percent_diff_recent_best            NaN -0.742832 -0.402534 -0.633585   \n",
       "percent_diff_recent_worst           NaN -0.834228       NaN -0.566721   \n",
       "no_mark_rate                        NaN       NaN       NaN       NaN   \n",
       "count                               NaN       NaN       NaN       NaN   \n",
       "year                                NaN       NaN       NaN       NaN   \n",
       "score                          0.814729       NaN       NaN       NaN   \n",
       "\n",
       "                                std    median  mean_three_recent  \\\n",
       "all_american                    NaN       NaN                NaN   \n",
       "min                       -0.863812  0.839157           0.868393   \n",
       "max                             NaN  0.941817           0.945981   \n",
       "mean                      -0.608691  0.994070           1.000000   \n",
       "std                        1.000000 -0.565123          -0.608691   \n",
       "median                    -0.565123  1.000000           0.994070   \n",
       "mean_three_recent         -0.608691  0.994070           1.000000   \n",
       "mean_three_best           -0.427707  0.956692           0.957523   \n",
       "mean_three_worst          -0.791583  0.930132           0.951560   \n",
       "percent_diff_recent_best   0.805915 -0.616570          -0.633585   \n",
       "percent_diff_recent_worst  0.915533 -0.517846          -0.566721   \n",
       "no_mark_rate                    NaN       NaN                NaN   \n",
       "count                           NaN       NaN                NaN   \n",
       "year                            NaN       NaN                NaN   \n",
       "score                           NaN       NaN                NaN   \n",
       "\n",
       "                           mean_three_best  mean_three_worst  \\\n",
       "all_american                           NaN               NaN   \n",
       "min                               0.757867          0.958043   \n",
       "max                               0.979613          0.832441   \n",
       "mean                              0.957523          0.951560   \n",
       "std                              -0.427707         -0.791583   \n",
       "median                            0.956692          0.930132   \n",
       "mean_three_recent                 0.957523          0.951560   \n",
       "mean_three_best                   1.000000          0.841396   \n",
       "mean_three_worst                  0.841396          1.000000   \n",
       "percent_diff_recent_best               NaN         -0.786998   \n",
       "percent_diff_recent_worst              NaN         -0.789165   \n",
       "no_mark_rate                           NaN               NaN   \n",
       "count                                  NaN               NaN   \n",
       "year                                   NaN               NaN   \n",
       "score                                  NaN               NaN   \n",
       "\n",
       "                           percent_diff_recent_best  \\\n",
       "all_american                                    NaN   \n",
       "min                                       -0.742832   \n",
       "max                                       -0.402534   \n",
       "mean                                      -0.633585   \n",
       "std                                        0.805915   \n",
       "median                                    -0.616570   \n",
       "mean_three_recent                         -0.633585   \n",
       "mean_three_best                                 NaN   \n",
       "mean_three_worst                          -0.786998   \n",
       "percent_diff_recent_best                   1.000000   \n",
       "percent_diff_recent_worst                  0.861893   \n",
       "no_mark_rate                                    NaN   \n",
       "count                                      0.557427   \n",
       "year                                            NaN   \n",
       "score                                           NaN   \n",
       "\n",
       "                           percent_diff_recent_worst  no_mark_rate     count  \\\n",
       "all_american                                     NaN           NaN       NaN   \n",
       "min                                        -0.834228           NaN       NaN   \n",
       "max                                              NaN           NaN       NaN   \n",
       "mean                                       -0.566721           NaN       NaN   \n",
       "std                                         0.915533           NaN       NaN   \n",
       "median                                     -0.517846           NaN       NaN   \n",
       "mean_three_recent                          -0.566721           NaN       NaN   \n",
       "mean_three_best                                  NaN           NaN       NaN   \n",
       "mean_three_worst                           -0.789165           NaN       NaN   \n",
       "percent_diff_recent_best                    0.861893           NaN  0.557427   \n",
       "percent_diff_recent_worst                   1.000000           NaN  0.504491   \n",
       "no_mark_rate                                     NaN           1.0       NaN   \n",
       "count                                       0.504491           NaN  1.000000   \n",
       "year                                             NaN           NaN       NaN   \n",
       "score                                            NaN           NaN       NaN   \n",
       "\n",
       "                           year     score  \n",
       "all_american                NaN  0.814729  \n",
       "min                         NaN       NaN  \n",
       "max                         NaN       NaN  \n",
       "mean                        NaN       NaN  \n",
       "std                         NaN       NaN  \n",
       "median                      NaN       NaN  \n",
       "mean_three_recent           NaN       NaN  \n",
       "mean_three_best             NaN       NaN  \n",
       "mean_three_worst            NaN       NaN  \n",
       "percent_diff_recent_best    NaN       NaN  \n",
       "percent_diff_recent_worst   NaN       NaN  \n",
       "no_mark_rate                NaN       NaN  \n",
       "count                       NaN       NaN  \n",
       "year                        1.0       NaN  \n",
       "score                       NaN  1.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_correlations = df.drop([\"name\", \"place\"], axis=1).corr(numeric_only=True)\n",
    "X_correlations[abs(X_correlations) > 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "- The min, max, mean, and median are highly correlated as expected. Consider selecting only one of the four.\n",
    "- The three *mean_* features highly correlated with min, max, mean, and median so they may not be very descriptive\n",
    "- The *percent_diff*  features have a strong negative correlation with min, max, mean, median\n",
    "- The *percent_diff*  features are highly correlated with standard deviation and count which was not expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_american                 0.814729\n",
       "min                          0.122397\n",
       "max                          0.286176\n",
       "mean                         0.207847\n",
       "std                          0.034175\n",
       "median                       0.208468\n",
       "mean_three_recent            0.207847\n",
       "mean_three_best              0.268128\n",
       "mean_three_worst             0.138837\n",
       "percent_diff_recent_best     0.054832\n",
       "percent_diff_recent_worst    0.036084\n",
       "no_mark_rate                -0.148302\n",
       "count                        0.122951\n",
       "year                         0.035511\n",
       "score                        1.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe which features correlate best with target\n",
    "X_correlations[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>all_american</th>\n",
       "      <th>score</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>percent_diff_recent_best</th>\n",
       "      <th>percent_diff_recent_worst</th>\n",
       "      <th>no_mark_rate</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966135</td>\n",
       "      <td>0.011727</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.974430</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event  all_american     score      mean       std  percent_diff_recent_best  \\\n",
       "0   100             1  1.000000  0.966135  0.011727                  0.013292   \n",
       "1   100             1  0.958333  0.974430  0.011425                  0.000230   \n",
       "\n",
       "   percent_diff_recent_worst  no_mark_rate  count  year  \n",
       "0                   0.017410           0.0     16     2  \n",
       "1                   0.007804           0.0      9     1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on correlation alone, the only descriptive statistic needed is mean so our feature reduced data would be\n",
    "X_fr_correlation = df[[\"event\", \"all_american\", \"score\", \"mean\", \"std\", \"percent_diff_recent_best\", \"percent_diff_recent_worst\", \"no_mark_rate\", \"count\", \"year\"]]\n",
    "X_fr_correlation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "See if either subset can be well approximated with fewer dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99944375, 0.99978942, 0.99996606, 0.99998224, 0.99999642,\n",
       "       0.99999869, 0.99999941, 0.99999979, 0.99999989, 0.99999995,\n",
       "       0.99999999, 1.        , 1.        ])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=X.shape[1])\n",
    "pca.fit(X)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5363202 , 0.79807738, 0.95851262, 0.97844427, 0.99559703,\n",
       "       0.99838493, 0.99927716, 0.99973622, 0.99985991, 0.9999376 ,\n",
       "       0.99998206, 1.        , 1.        ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proof that the count feature in unscaled form was too much\n",
    "# 99% variance with 5 features\n",
    "X_count_scaled = X.copy()\n",
    "X_count_scaled[\"count\"] = X_scaled[\"count\"].copy()\n",
    "\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "pca.fit(X_count_scaled)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59059757, 0.79225125, 0.93488583, 0.95773049, 0.97441762,\n",
       "       0.98670203, 0.99598333, 0.99836088, 0.9992041 , 0.99959171,\n",
       "       0.99983998, 0.99993166, 0.99998767, 1.        , 1.        ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try PCA with all scaled\n",
    "# 99% variance with 7 features\n",
    "pca = PCA(n_components=X_scaled.shape[1])\n",
    "pca.fit(X_scaled)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, scaled or unscaled PCA should be highly effective for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 15) (96, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, RandomizedSearchCV\n",
    "\n",
    "# Need the binary class target for KNN but will try \"continuous\" score for regression\n",
    "X_train, X_test, y_score_train, y_score_test = train_test_split(X_scaled, y_score, test_size=4/18, random_state=0, stratify=df[\"event\"])\n",
    "_, _, y_all_am_train, y_all_am_test = train_test_split(X_scaled, y_all_am, test_size=4/18, random_state=0, stratify=df[\"event\"])\n",
    "assert sum([1 if x > 0.7 else 0 for x in y_score_train] == y_all_am_train) # assert we got data in the same order thus we don't need second Xs\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make two simple arguments about correctness of predictons before training any model. We know, that the predictions should not go above 1. Secondly, our labels are uniformly distributed so our predictions should be as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.histogram(y_score_test, bins=8, c='b')\n",
    "ptt.historam(y_score_all_am, bins=8, c='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel=\"linear\")\n",
    "svm.fit(X_train, y_all_am_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "predictions = svm.predict(X_train)\n",
    "print(accuracy_score(predictions, y_all_am_train))\n",
    "print(f1_score(y_all_am_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = SVR(kernel=\"poly\", degree=5)\n",
    "svm.fit(X_train, y_score_train)\n",
    "plt.hist(svm.predict(X_train), bins=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1004778278400194,\n",
       " 1.1002894115507702,\n",
       " 1.1001437810721248,\n",
       " 1.0998833665654135,\n",
       " 1.099821971593929,\n",
       " 1.0996933983397228,\n",
       " 1.0931263409963858,\n",
       " 1.068980302781321,\n",
       " 1.0598735614186148,\n",
       " 1.055958833548002]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error, mean_squared_error, mean_absolute_error\n",
    "predictions = svm.predict(X_train)\n",
    "sorted(predictions, reverse=True)[:10]\n",
    "# for metric in [max_error, mean_squared_error, mean_absolute_error]:\n",
    "#     print(metric(predictions, y_score_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1004778278400194,\n",
       " 1.1002894115507702,\n",
       " 1.1001437810721248,\n",
       " 1.0998833665654135,\n",
       " 1.099821971593929,\n",
       " 1.0996933983397228,\n",
       " 1.0931263409963858,\n",
       " 1.068980302781321,\n",
       " 1.0598735614186148,\n",
       " 1.055958833548002]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error, mean_squared_error, mean_absolute_error\n",
    "predictions = svm.predict(X_train)\n",
    "sorted(predictions, reverse=True)[:10]\n",
    "# for metric in [max_error, mean_squared_error, mean_absolute_error]:\n",
    "#     print(metric(predictions, y_score_train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tfrrs': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "429b51c6b84d21d7646721574e539afba211ecf3c8246758e7ac99ea26dd71d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

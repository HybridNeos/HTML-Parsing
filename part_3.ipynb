{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the data\n",
    "\n",
    "To avoid features being derived from other features split the data into subsets *mean_* and *percent_* features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "global df\n",
    "df = pd.read_csv(\"./data/processed/raw.csv\")\n",
    "df.drop([\"school\", \"q1\", \"q3\", \"grade\"], axis=1, inplace=True)\n",
    "X = df.drop([\"name\", \"event\", \"place\", \"all_american\", \"score\"], axis=1)\n",
    "# Revisit part 2 and scale count\n",
    "X[\"year\"] /= 4\n",
    "\n",
    "y_score = df[\"score\"]\n",
    "y_all_am = df[\"all_american\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"event_num\"] = le.fit_transform(df[\"event\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare scaled data for later\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "columns = list(X.columns[:-1]) # Year scaling is dividing by 4\n",
    "X_scaled_np = scaler.fit_transform(X.drop([\"year\"], axis=1))\n",
    "X_scaled = pd.DataFrame(X_scaled_np, columns=columns)\n",
    "#X_scaled = pd.concat([df[[\"all_american\", \"score\"]], X_scaled, df[\"year\"]], axis=1)\n",
    "X_scaled = pd.concat([X_scaled, df[\"year\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Count ranges up to 75 so scale this down in original data\n",
    "X[\"count\"] = X_scaled[\"count\"].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline\n",
    "\n",
    "Given that there are 24 athletes competing in an event but only 8 place All-American the completely random chance of guessing correctly is 1/3. I want to create a custom metric which shows how many of the top 8 were predicted correctly for each event. By doing so, we can make a more intelligent baseline if we simply predict the top 8 athletes in an event based on a given feature to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mean_three_best', 0.729), ('max', 0.681), ('median', 0.59), ('mean', 0.576), ('mean_three_recent', 0.576)]\n"
     ]
    }
   ],
   "source": [
    "def percent_all_american_score(y_true, y_pred, indices=df.index):\n",
    "    truth = df.iloc[indices][[\"name\", \"event\", \"place\", \"all_american\"]].copy()\n",
    "    truth[\"prob_all_am\"] = y_pred\n",
    "    top_eight = truth.sort_values([\"event\", \"prob_all_am\"], ascending=False).groupby([\"event\"]).head(8)\n",
    "    return sum(top_eight[\"all_american\"]) / len(top_eight)\n",
    "\n",
    "single_feature_scores = [(feature, round(percent_all_american_score(None, X[feature]), 3)) for feature in X.columns]\n",
    "print(sorted(single_feature_scores, key=lambda tup: tup[1], reverse=True)[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, my feature engineered `mean_three_best` alone nearly 73 percent accurate! If the models can not beat *0.729* we can determine that either 1) we need to collect more data and/or features or 2) this problem is not well suited to machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "all_am_accuracy = make_scorer(percent_all_american_score, needs_proba=True, indices=df.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Correlation\n",
    "First, we check if any features are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                             all_am       min       max      mean       std  \\\nall_american               1.000000       NaN       NaN       NaN       NaN   \nmin                             NaN  1.000000  0.746160  0.868393 -0.863812   \nmax                             NaN  0.746160  1.000000  0.945981       NaN   \nmean                            NaN  0.868393  0.945981  1.000000 -0.608691   \nstd                             NaN -0.863812       NaN -0.608691  1.000000   \nmedian                          NaN  0.839157  0.941817  0.994070 -0.565123   \nmean_three_recent               NaN  0.868393  0.945981  1.000000 -0.608691   \nmean_three_best                 NaN  0.757867  0.979613  0.957523 -0.427707   \nmean_three_worst                NaN  0.958043  0.832441  0.951560 -0.791583   \npercent_diff_recent_best        NaN -0.742832 -0.402534 -0.633585  0.805915   \npercent_diff_recent_worst       NaN -0.834228       NaN -0.566721  0.915533   \nno_mark_rate                    NaN       NaN       NaN       NaN       NaN   \ncount                           NaN       NaN       NaN       NaN       NaN   \nyear                            NaN       NaN       NaN       NaN       NaN   \nscore                      0.814729       NaN       NaN       NaN       NaN   \n\n                             median  mean_3_recent  mean_3_best  mean_3_worst  \\\nall_american                    NaN            NaN          NaN           NaN   \nmin                        0.839157       0.868393     0.757867      0.958043   \nmax                        0.941817       0.945981     0.979613      0.832441   \nmean                       0.994070       1.000000     0.957523      0.951560   \nstd                       -0.565123      -0.608691    -0.427707     -0.791583   \nmedian                     1.000000       0.994070     0.956692      0.930132   \nmean_three_recent          0.994070       1.000000     0.957523      0.951560   \nmean_three_best            0.956692       0.957523     1.000000      0.841396   \nmean_three_worst           0.930132       0.951560     0.841396      1.000000   \npercent_diff_recent_best  -0.616570      -0.633585          NaN     -0.786998   \npercent_diff_recent_worst -0.517846      -0.566721          NaN     -0.789165   \nno_mark_rate                    NaN            NaN          NaN           NaN   \ncount                           NaN            NaN          NaN           NaN   \nyear                            NaN            NaN          NaN           NaN   \nscore                           NaN            NaN          NaN           NaN   \n\n                           pd_recent_best  pd_recent_worst  no_mark_rate  \\\nall_american                          NaN              NaN           NaN   \nmin                             -0.742832        -0.834228           NaN   \nmax                             -0.402534              NaN           NaN   \nmean                            -0.633585        -0.566721           NaN   \nstd                              0.805915         0.915533           NaN   \nmedian                          -0.616570        -0.517846           NaN   \nmean_three_recent               -0.633585        -0.566721           NaN   \nmean_three_best                       NaN              NaN           NaN   \nmean_three_worst                -0.786998        -0.789165           NaN   \npercent_diff_recent_best         1.000000         0.861893           NaN   \npercent_diff_recent_worst        0.861893         1.000000           NaN   \nno_mark_rate                          NaN              NaN           1.0   \ncount                            0.557427         0.504491           NaN   \nyear                                  NaN              NaN           NaN   \nscore                                 NaN              NaN           NaN   \n\n                              count  year     score  \nall_american                    NaN   NaN  0.814729  \nmin                             NaN   NaN       NaN  \nmax                             NaN   NaN       NaN  \nmean                            NaN   NaN       NaN  \nstd                             NaN   NaN       NaN  \nmedian                          NaN   NaN       NaN  \nmean_three_recent               NaN   NaN       NaN  \nmean_three_best                 NaN   NaN       NaN  \nmean_three_worst                NaN   NaN       NaN  \npercent_diff_recent_best   0.557427   NaN       NaN  \npercent_diff_recent_worst  0.504491   NaN       NaN  \nno_mark_rate                    NaN   NaN       NaN  \ncount                      1.000000   NaN       NaN  \nyear                            NaN   1.0       NaN  \nscore                           NaN   NaN  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>all_am</th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>median</th>\n      <th>mean_3_recent</th>\n      <th>mean_3_best</th>\n      <th>mean_3_worst</th>\n      <th>pd_recent_best</th>\n      <th>pd_recent_worst</th>\n      <th>no_mark_rate</th>\n      <th>count</th>\n      <th>year</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>all_american</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.814729</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.746160</td>\n      <td>0.868393</td>\n      <td>-0.863812</td>\n      <td>0.839157</td>\n      <td>0.868393</td>\n      <td>0.757867</td>\n      <td>0.958043</td>\n      <td>-0.742832</td>\n      <td>-0.834228</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>0.746160</td>\n      <td>1.000000</td>\n      <td>0.945981</td>\n      <td>NaN</td>\n      <td>0.941817</td>\n      <td>0.945981</td>\n      <td>0.979613</td>\n      <td>0.832441</td>\n      <td>-0.402534</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>0.868393</td>\n      <td>0.945981</td>\n      <td>1.000000</td>\n      <td>-0.608691</td>\n      <td>0.994070</td>\n      <td>1.000000</td>\n      <td>0.957523</td>\n      <td>0.951560</td>\n      <td>-0.633585</td>\n      <td>-0.566721</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>-0.863812</td>\n      <td>NaN</td>\n      <td>-0.608691</td>\n      <td>1.000000</td>\n      <td>-0.565123</td>\n      <td>-0.608691</td>\n      <td>-0.427707</td>\n      <td>-0.791583</td>\n      <td>0.805915</td>\n      <td>0.915533</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>NaN</td>\n      <td>0.839157</td>\n      <td>0.941817</td>\n      <td>0.994070</td>\n      <td>-0.565123</td>\n      <td>1.000000</td>\n      <td>0.994070</td>\n      <td>0.956692</td>\n      <td>0.930132</td>\n      <td>-0.616570</td>\n      <td>-0.517846</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean_three_recent</th>\n      <td>NaN</td>\n      <td>0.868393</td>\n      <td>0.945981</td>\n      <td>1.000000</td>\n      <td>-0.608691</td>\n      <td>0.994070</td>\n      <td>1.000000</td>\n      <td>0.957523</td>\n      <td>0.951560</td>\n      <td>-0.633585</td>\n      <td>-0.566721</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean_three_best</th>\n      <td>NaN</td>\n      <td>0.757867</td>\n      <td>0.979613</td>\n      <td>0.957523</td>\n      <td>-0.427707</td>\n      <td>0.956692</td>\n      <td>0.957523</td>\n      <td>1.000000</td>\n      <td>0.841396</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean_three_worst</th>\n      <td>NaN</td>\n      <td>0.958043</td>\n      <td>0.832441</td>\n      <td>0.951560</td>\n      <td>-0.791583</td>\n      <td>0.930132</td>\n      <td>0.951560</td>\n      <td>0.841396</td>\n      <td>1.000000</td>\n      <td>-0.786998</td>\n      <td>-0.789165</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>percent_diff_recent_best</th>\n      <td>NaN</td>\n      <td>-0.742832</td>\n      <td>-0.402534</td>\n      <td>-0.633585</td>\n      <td>0.805915</td>\n      <td>-0.616570</td>\n      <td>-0.633585</td>\n      <td>NaN</td>\n      <td>-0.786998</td>\n      <td>1.000000</td>\n      <td>0.861893</td>\n      <td>NaN</td>\n      <td>0.557427</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>percent_diff_recent_worst</th>\n      <td>NaN</td>\n      <td>-0.834228</td>\n      <td>NaN</td>\n      <td>-0.566721</td>\n      <td>0.915533</td>\n      <td>-0.517846</td>\n      <td>-0.566721</td>\n      <td>NaN</td>\n      <td>-0.789165</td>\n      <td>0.861893</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.504491</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>no_mark_rate</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.557427</td>\n      <td>0.504491</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>score</th>\n      <td>0.814729</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_correlations = df.drop([\"name\", \"place\", \"event_num\"], axis=1).corr()\n",
    "X_correlations.columns = [\n",
    "    'all_am', 'min', 'max', 'mean', 'std', 'median',\n",
    "    'mean_3_recent', 'mean_3_best', 'mean_3_worst',\n",
    "    'pd_recent_best', 'pd_recent_worst', 'no_mark_rate',\n",
    "    'count', 'year', 'score'\n",
    "] # To fit the dataframe on screen\n",
    "X_correlations[abs(X_correlations) > 0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Observations\n",
    "- The min, max, mean, and median are highly correlated as expected. Consider selecting only one of the four.\n",
    "- The three *mean_* features highly correlated with min, max, mean, and median so they may not be very descriptive\n",
    "- The *percent_diff*  features have a strong negative correlation with min, max, mean, median\n",
    "- The *percent_diff*  features are highly correlated with standard deviation and count which was not expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because the `min, max, median`,  `mean_three_recent, mean_three_best, mean_three_worst`, and `percent_diff_recent_best, percent_diff_recent_worst` feature groups are so strongly correlated I will pick only one based on the strongest correlation to target. This additionally lightens the problem of the percent_diff features being linear combinations of the mean_ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "all_american                 0.814729\nmin                          0.122397\nmax                          0.286176\nmean                         0.207847\nstd                          0.034175\nmedian                       0.208468\nmean_three_recent            0.207847\nmean_three_best              0.268128\nmean_three_worst             0.138837\npercent_diff_recent_best     0.054832\npercent_diff_recent_worst    0.036084\nno_mark_rate                -0.148302\ncount                        0.122951\nyear                         0.035511\nscore                        1.000000\nName: score, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe which features correlate best with target\n",
    "X_correlations[\"score\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, the `max, mean_three_best, percent_diff_recent_best` features win their groups respectively and so based on correlation our feature reduced data will be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        max       std  mean_three_best  percent_diff_recent_best  \\\n0  0.982000  0.011727         0.979063                  0.013292   \n1  1.003064  0.011425         0.974206                  0.000230   \n2  0.974206  0.015418         0.974206                  0.015742   \n3  0.987928  0.013936         0.979063                  0.013061   \n4  0.979063  0.011750         0.972277                  0.011381   \n\n   no_mark_rate     count  year  \n0           0.0  0.180556  0.50  \n1           0.0  0.083333  0.25  \n2           0.0  0.180556  0.50  \n3           0.0  0.208333  0.75  \n4           0.0  0.194444  1.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max</th>\n      <th>std</th>\n      <th>mean_three_best</th>\n      <th>percent_diff_recent_best</th>\n      <th>no_mark_rate</th>\n      <th>count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.982000</td>\n      <td>0.011727</td>\n      <td>0.979063</td>\n      <td>0.013292</td>\n      <td>0.0</td>\n      <td>0.180556</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.003064</td>\n      <td>0.011425</td>\n      <td>0.974206</td>\n      <td>0.000230</td>\n      <td>0.0</td>\n      <td>0.083333</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.974206</td>\n      <td>0.015418</td>\n      <td>0.974206</td>\n      <td>0.015742</td>\n      <td>0.0</td>\n      <td>0.180556</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.987928</td>\n      <td>0.013936</td>\n      <td>0.979063</td>\n      <td>0.013061</td>\n      <td>0.0</td>\n      <td>0.208333</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.979063</td>\n      <td>0.011750</td>\n      <td>0.972277</td>\n      <td>0.011381</td>\n      <td>0.0</td>\n      <td>0.194444</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thus by correlation the feature reduced data would be max, std, percent_diff_recent_best, no_mark_rate, count, and year\n",
    "# = df[[\"event\", \"all_american\", \"score\", \"max\", \"std\", \"percent_diff_recent_best\", \"no_mark_rate\", \"count\", \"year\"]]\n",
    "X_fr_corr = X[[\"max\", \"std\", \"mean_three_best\", \"percent_diff_recent_best\", \"no_mark_rate\", \"count\", \"year\"]]\n",
    "X_fr_corr.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Feature Importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('max', 0.242), ('percent_diff_recent_best', 0.135), ('percent_diff_recent_worst', 0.132), ('min', 0.093), ('std', 0.067), ('count', 0.066), ('mean_three_recent', 0.062), ('mean_three_worst', 0.054), ('no_mark_rate', 0.047), ('mean_three_best', 0.044), ('median', 0.031), ('year', 0.015), ('mean', 0.011)]\n"
     ]
    }
   ],
   "source": [
    "dt_features = DecisionTreeClassifier(random_state=0, class_weight=\"balanced\")\n",
    "dt_features.fit(X, y_all_am)\n",
    "print(sorted([(pair[0], round(pair[1], 3)) for pair in zip(X.columns, dt_features.feature_importances_)], reverse=True, key=lambda tup: tup[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The feature importance values here align with what we found in the correlation tests. Namely, max is the most important feature with count and percent_diff_recent_best also being relevant. So, if we combine what we know so far a feature reduced dataset should only include the columns `max, std, percent_diff_recent_best, no_mark_rate, count, year`. Given this, there is no change to the feature reduced dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "        max       std  mean_three_best  percent_diff_recent_best  \\\n0  0.982000  0.011727         0.979063                  0.013292   \n1  1.003064  0.011425         0.974206                  0.000230   \n2  0.974206  0.015418         0.974206                  0.015742   \n3  0.987928  0.013936         0.979063                  0.013061   \n4  0.979063  0.011750         0.972277                  0.011381   \n\n   no_mark_rate     count  year  \n0           0.0  0.180556  0.50  \n1           0.0  0.083333  0.25  \n2           0.0  0.180556  0.50  \n3           0.0  0.208333  0.75  \n4           0.0  0.194444  1.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max</th>\n      <th>std</th>\n      <th>mean_three_best</th>\n      <th>percent_diff_recent_best</th>\n      <th>no_mark_rate</th>\n      <th>count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.982000</td>\n      <td>0.011727</td>\n      <td>0.979063</td>\n      <td>0.013292</td>\n      <td>0.0</td>\n      <td>0.180556</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.003064</td>\n      <td>0.011425</td>\n      <td>0.974206</td>\n      <td>0.000230</td>\n      <td>0.0</td>\n      <td>0.083333</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.974206</td>\n      <td>0.015418</td>\n      <td>0.974206</td>\n      <td>0.015742</td>\n      <td>0.0</td>\n      <td>0.180556</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.987928</td>\n      <td>0.013936</td>\n      <td>0.979063</td>\n      <td>0.013061</td>\n      <td>0.0</td>\n      <td>0.208333</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.979063</td>\n      <td>0.011750</td>\n      <td>0.972277</td>\n      <td>0.011381</td>\n      <td>0.0</td>\n      <td>0.194444</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fr = X_fr_corr\n",
    "X_fr_scaled = X_scaled[X_fr.columns]\n",
    "X_fr.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA\n",
    "See if the data scaled or unscaled can be well approximated with fewer dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5363202 , 0.79807738, 0.95851262, 0.97844427, 0.99559703,\n       0.99838493, 0.99927716, 0.99973622, 0.99985991, 0.9999376 ,\n       0.99998206, 1.        , 1.        ])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 99% variance with 5 features\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "X_pca = pca.fit_transform(X)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.71956614, 0.93331849, 0.963029  , 0.98342368, 0.99504626,\n       0.99798369, 0.99902705, 0.99949987, 0.99980473, 0.99991648,\n       0.99998495, 1.        , 1.        ])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try PCA with all scaled\n",
    "# 99% variance with 7 features\n",
    "pca_scaled = PCA(n_components=X_scaled.shape[1])\n",
    "X_pca_scaled = pca_scaled.fit(X_scaled)\n",
    "np.cumsum(pca_scaled.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # If we perform PCA on the scaled and correlation selected features, we get a stronger first 3 variances and still 99% after 5\n",
    "# # This means that plotting in 2 dimensions might feasible\n",
    "# pca_corr = PCA(n_components=X_fr.shape[1])\n",
    "# pca_corr.fit(X_fr)\n",
    "# np.cumsum(pca_corr.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.85224582, 0.93433934, 0.96366531, 0.98694513, 0.99753656,\n       0.99936495, 1.        ])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The scaled set selected by feature reduction is very notably stronger with the first component and very slightly better on the second component.\n",
    "# It also gets to the 99% variance by the 5th component so there is nothing too\n",
    "pca_corr = PCA(n_components=X_fr_scaled.shape[1])\n",
    "pca_corr.fit(X_scaled[X_fr_scaled.columns])\n",
    "np.cumsum(pca_corr.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In conclusion, PCA should be effective for our data. However, because the dataset is small and already has few impactful features I am not planning to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While not originally planned, because the PCA explained_variance of two features was higher than expected I wanted to try visualizing the data projected into two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = X_fr_corr\n",
    "viz_pca = PCA(n_components=2)\n",
    "points = viz_pca.fit_transform(data)\n",
    "\n",
    "colors = [\"blue\" if x == 1 else \"orange\" for x in y_all_am]\n",
    "all_am_indexes = y_all_am == 1\n",
    "\n",
    "plt.scatter(x=points[all_am_indexes,0], y=points[all_am_indexes,1], c=\"blue\")\n",
    "plt.scatter(x=points[np.invert(all_am_indexes),0], y=points[np.invert(all_am_indexes),1], c=\"orange\", alpha=0.6)\n",
    "plt.legend([\"All American\", \"Not All American\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the end, the projection into two dimensions only gives a discouraging sign as to the class seperability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "Splitting for this dataset is mildly tricky. We are assuming that event doesn't matter for predictions but we ultimately need a ranking within the event groups. With there being 18 event groups I want to split the data by 13 events for training and 5 for test which is about 72%, 28% train test split. If we want a validation set we can select 3 events from training to be a validation set.\n",
    "\n",
    "When we do cross validation for hyperparameter tuning in part 4 we will be making multiple splits. However, we only need one for now to determine the best model to go forward with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, LeavePGroupsOut, RandomizedSearchCV\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311, 7)\n",
      "(311, 13)\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def train_test_split_on_event(x_type=\"scaled\", y_type=\"all_am\", num_test_events=5):\n",
    "    # We can try the binary classification or continuous target variable.\n",
    "    y_data = y_all_am if y_type.lower() == \"all_am\" else y_score\n",
    "\n",
    "    # There are multiple options to try for our data. We will try some but also explore more in part 4.\n",
    "    x_type = x_type.lower()\n",
    "    if x_type == \"scaled\":\n",
    "        X_data = X_scaled\n",
    "    elif x_type == \"fr\":\n",
    "        X_data = X_fr\n",
    "    elif x_type == \"fr_scaled\":\n",
    "        X_data = X_fr_scaled\n",
    "    # elif x_type == \"pca\":\n",
    "    #     X_data = X_pca\n",
    "    # elif x_type == \"pca_scaled\":\n",
    "    #     X_data = X_pca_scaled\n",
    "    else:\n",
    "        X_data = X # slightly better on SVM\n",
    "\n",
    "    test_numbers = random.choices(range(18), k=num_test_events)\n",
    "\n",
    "    test_indices = df[df[\"event_num\"].isin(test_numbers)].index\n",
    "    X_test = X_data.iloc[test_indices]\n",
    "    y_test = y_data.iloc[test_indices]\n",
    "\n",
    "    train_indices = df[~df[\"event_num\"].isin(test_numbers)].index\n",
    "    X_train = X_data.iloc[train_indices]\n",
    "    y_train = y_data.iloc[train_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_fr_train, X_fr_test, y_train, y_test = train_test_split_on_event(x_type=\"fr\", y_type=\"all_am\")\n",
    "print(X_fr_train.shape)\n",
    "X_scaled_train, X_scaled_test, _, _ = train_test_split_on_event(x_type=\"scaled\", y_type=\"all_am\")\n",
    "print(X_scaled_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, there are many possible different permutations of the data to consider. However, I will focus more on the feature reduced dataset and the scaled data as they both are transformations from part 2. Moreover, based on PCA cumulative variances both datasets should show improvements over the unmodified dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 1 - Spectral Clustering\n",
    "For the unsupervised model I wanted to select a model I haven't used before and I landed on spectral clustering because I appreciate graphs and because it has many hyperparameters to  tune."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup\n",
    "In addition to importing the model we are going to use I am going to import two metrics recommend by [sklearn documentation](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import rand_score, fowlkes_mallows_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we can use the sklearn recommend metrics for evaluating unsupervised clusters, there is a way to recover the multiclass labels of the clustering algorithm into the binary classification we have. If we try the different combinations of flattening the labels to binary labels (example here)\n",
    "```\n",
    "Mapping = (0, 2)\n",
    "Predicted = [0, 1, 1, 2, 0, 2, 3, 1]\n",
    "Mapped    = [1, 0, 0, 1, 0, 1, 0, 0]\n",
    "```\n",
    "we can then use our traditional supervised learning metrics. Crucially, we know that we want to predict about 8 out of 24 athletes to be all_american. So, we want to find the permutation of the labels which will assign about 1/3rd of the labels to our positive class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Taken from https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def best_mapping(clf, y_actual):\n",
    "    k_powerset = list(powerset(range(clf.n_clusters)))\n",
    "    mapped = [[1 if label in mapping else 0 for label in clf.labels_] for mapping in k_powerset]\n",
    "    mapped_scores = [(k_powerset[i], round(f1_score(preds, y_actual), 3), round(np.mean(preds), 3)) for i, preds in enumerate(mapped)]\n",
    "    return filter(lambda vals: 0.3 < vals[2] < 0.4, sorted(mapped_scores, key=lambda tup: tup[1], reverse=True))\n",
    "\n",
    "def print_clustering_metrics(labels_pred, y_train):\n",
    "    print(f\"\\tRand score {round(rand_score(labels_pred, y_train), 3)}\")\n",
    "    print(f\"\\tFowlkes Mallows score {round(fowlkes_mallows_score(labels_pred, y_train), 3)}\")\n",
    "    print(f\"\\tBest (mapping, f1_score, percent_positive) {list(best_mapping(clustering, y_train))[:1]}\")\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature reduced data\n",
      "\tRand score 0.474\n",
      "\tFowlkes Mallows score 0.358\n",
      "\tBest (mapping, f1_score, percent_positive) [((0, 3), 0.411, 0.386)]\n",
      "\n",
      "Scaled data\n",
      "\tRand score 0.471\n",
      "\tFowlkes Mallows score 0.396\n",
      "\tBest (mapping, f1_score, percent_positive) [((2, 3), 0.317, 0.334)]\n"
     ]
    }
   ],
   "source": [
    "# From our PCA we saw that it reached 99% variance with so 5 components, so we will try that many clusters\n",
    "clustering = SpectralClustering(n_clusters=5, assign_labels=\"cluster_qr\", random_state=0).fit(X_fr_train)\n",
    "labels_pred = clustering.labels_\n",
    "\n",
    "print(\"Feature reduced data\")\n",
    "print_clustering_metrics(labels_pred, y_train)\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=5, assign_labels=\"cluster_qr\", random_state=0).fit(X_scaled_train)\n",
    "labels_pred = clustering.labels_\n",
    "\n",
    "print(\"\\nScaled data\")\n",
    "print_clustering_metrics(labels_pred, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The two datasets have similar performance here. However, their performance is not very exciting. I want to see if we can tune the model further using the feature reduced dataset because the number of labels for SpectralClustering is at most the number of features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature reduced data 2 clusters\n",
      "\tRand score 0.502\n",
      "\tFowlkes Mallows score 0.546\n",
      "\tBest (mapping, f1_score, percent_positive) [((0,), 0.329, 0.35)]\n",
      "\n",
      "Feature reduced data 7 clusters\n",
      "\tRand score 0.463\n",
      "\tFowlkes Mallows score 0.319\n",
      "\tBest (mapping, f1_score, percent_positive) [((0, 2, 4), 0.396, 0.395)]\n"
     ]
    }
   ],
   "source": [
    "# Decrease the number of clusters\n",
    "clustering = SpectralClustering(n_clusters=2, random_state=0).fit(X_fr_train)\n",
    "labels_pred = clustering.labels_\n",
    "\n",
    "print(\"Feature reduced data 2 clusters\")\n",
    "print_clustering_metrics(labels_pred, y_train)\n",
    "\n",
    "# Increase the number of clusters\n",
    "clustering = SpectralClustering(n_clusters=X_fr_train.shape[1], random_state=0).fit(X_fr_train)\n",
    "labels_pred = clustering.labels_\n",
    "\n",
    "print(f\"\\nFeature reduced data {X_fr_train.shape[1]} clusters\")\n",
    "print_clustering_metrics(labels_pred, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model performs better on recommend metrics with two clusters however five clusters still seems to be the best. So, we will fix the number of clusters and play with other hyperparameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Five clusters with nearest_neighbors affinity 7\n",
      "\tRand score 0.474\n",
      "\tFowlkes Mallows score 0.374\n",
      "\tBest (mapping, f1_score, percent_positive) [((2, 3), 0.4, 0.389)]\n",
      "\n",
      "Five clusters with degree 3 polynomial kernel and discretize labels\n",
      "\tRand score 0.472\n",
      "\tFowlkes Mallows score 0.355\n",
      "\tBest (mapping, f1_score, percent_positive) [((2, 3), 0.383, 0.354)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mark3\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:259: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Try a different affinity measure\n",
    "clustering = SpectralClustering(\n",
    "    n_clusters=5,\n",
    "    affinity=\"nearest_neighbors\",\n",
    "    random_state=0\n",
    "    ).fit(X_fr_train)\n",
    "labels_pred = clustering.labels_\n",
    "print(f\"\\nFive clusters with nearest_neighbors affinity {X_fr_train.shape[1]}\")\n",
    "print_clustering_metrics(labels_pred, y_train)\n",
    "\n",
    "# Use a kernel and different method of assigning labels\n",
    "clustering = SpectralClustering(\n",
    "    n_clusters=5,\n",
    "    affinity=\"poly\",\n",
    "    degree=3,\n",
    "    assign_labels=\"discretize\",\n",
    "    random_state=0\n",
    "    ).fit(X_fr_train)\n",
    "labels_pred = clustering.labels_\n",
    "\n",
    "print(f\"\\nFive clusters with degree 3 polynomial kernel and discretize labels\")\n",
    "print_clustering_metrics(labels_pred, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spectral Clustering conclusion\n",
    "\n",
    "There are many different permutations of hyperparameters to try here. However, there seems to be a wall at around 0.5 for the rand and fowlkes mallows score alongside a wall at 0.4 for my converted f1 score. Given how well the baseline performed, I think we can conclude that this model is not a good for the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 2 - Logistic Regression\n",
    "\n",
    "Since athlete performance will naturally vary it makes sense to predict a probability that an athlete will finish as an all american. Thus, logistic regression is a natural choice of model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature reduction and training\n",
    "\n",
    "Because we have a small dataset it is actually feasible to perform an exhaustive search for the optimal feature set. I waited to do this on the supervised data as I imagine it can be helpful for both models.\n",
    "\n",
    "I will be using the forward direction because as our baseline showed even one column is very powerful. Additionally, I will be using the f1_score metric because the labels are inbalanced thus we need a more robust metric than accuracy. If we set the number of features to be 7 based on our earlier feature reduction we get"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_on_event(y_type=\"all_am\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['min' 'max' 'std' 'mean_three_worst' 'percent_diff_recent_best'\n",
      " 'percent_diff_recent_worst' 'no_mark_rate']\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "sfs = SequentialFeatureSelector(lr, n_features_to_select=7, direction=\"forward\", scoring=f1_scorer, cv=5)\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "print(sfs.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "which when compared to our original"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['max', 'std', 'mean_three_best', 'percent_diff_recent_best',\n       'no_mark_rate', 'count', 'year'],\n      dtype='object')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fr.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "show that the two are very close sharing five features in common. Additionally, if we re-run this selection again to auto select based on a tolerance we get the following features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['min' 'std' 'mean_three_worst' 'percent_diff_recent_best'\n",
      " 'percent_diff_recent_worst' 'no_mark_rate']\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "sfs = SequentialFeatureSelector(lr, n_features_to_select=\"auto\", direction=\"forward\", scoring=f1_scorer, cv=5)\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "print(sfs.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use this dataset, dubbed X_sequential, for evaluation of logistic regression."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mean_three_worst', 1.786), ('std', 1.697), ('percent_diff_recent_worst', 1.381), ('percent_diff_recent_best', 1.213), ('min', 0.592), ('no_mark_rate', -0.987)]\n"
     ]
    }
   ],
   "source": [
    "# See the feature importances\n",
    "X_sequential = sfs.transform(X_train)\n",
    "lr.fit(X_sequential, y_train)\n",
    "print(sorted([(x, round(y, 3)) for x, y in zip(sfs.get_feature_names_out(), lr.coef_[0])], key=lambda tup: tup[1], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with default params\n",
      "\tf1 score: 0.5657\n",
      "\tpercent positive: 0.4742\n",
      "\tall american accuracy 0.5576923076923077\n"
     ]
    }
   ],
   "source": [
    "# Get the scores\n",
    "labels_pred = lr.predict(X_sequential)\n",
    "prob_preds = lr.predict_proba(X_sequential)[:, 1] # gives probability for 0 then 1\n",
    "print(\"Logistic regression with default params\")\n",
    "print(f\"\\tf1 score: {round(f1_score(labels_pred, y_train), 4)}\")\n",
    "print(f\"\\tpercent positive: {round(np.mean(labels_pred), 4)}\")\n",
    "print(f\"\\tall american accuracy {percent_all_american_score(None, prob_preds, X_train.index)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sequentially selected data gives us shockingly similar values for our metrics. However, the 56% positive is concerning as the goal is 33%. So, we will adjust the regularization to see if we can get better performances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression with C=0.01\n",
      "\tf1 score: 0.4608\n",
      "\tpercent positive: 0.3645\n",
      "\tall american accuracy 0.4423076923076923\n",
      "\n",
      "Logistic regression with C=0.1\n",
      "\tf1 score: 0.4679\n",
      "\tpercent positive: 0.3677\n",
      "\tall american accuracy 0.47115384615384615\n",
      "\n",
      "Logistic regression with C=1\n",
      "\tf1 score: 0.5657\n",
      "\tpercent positive: 0.4742\n",
      "\tall american accuracy 0.5576923076923077\n",
      "\n",
      "Logistic regression with C=10\n",
      "\tf1 score: 0.56\n",
      "\tpercent positive: 0.471\n",
      "\tall american accuracy 0.5769230769230769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    clf = LogisticRegression(C=C, class_weight=\"balanced\")\n",
    "    clf.fit(X_sequential, y_train)\n",
    "\n",
    "    labels_pred = clf.predict(X_sequential)\n",
    "    prob_preds = clf.predict_proba(X_sequential)[:, 1] # gives probability for 0 then 1\n",
    "    print(f\"Logistic regression with C={C}\")\n",
    "    print(f\"\\tf1 score: {round(f1_score(labels_pred, y_train), 4)}\")\n",
    "    print(f\"\\tpercent positive: {round(np.mean(labels_pred), 4)}\")\n",
    "    print(f\"\\tall american accuracy {percent_all_american_score(None, prob_preds, X_train.index)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression Conclusion\n",
    "While lowering the regularization did improve the model performance on training data it is still not ideal. The accuracy is respectable only because it is predicting too many positive labels (note that training on full feature set increased the ratio of positive predictions even further). So, even though logistic regression confirmed that we do not need many of the features collected it still did not beat our very high baseline and does not fit the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model 3 - SVM\n",
    "\n",
    "For the final model I want to go with SVM. The reasons for this are twofold: First, given that the two previous models have not been excellent I am hoping that the SVM kernel will bring out separability from the data. Additionally, SVM gives us a new tool in the form of regression. To recall, I prepared a \"continuous\" target variable `score` which we can try in addition to the binary target variable to see if this more rich data creates better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "  event  place     score  all_american\n0   100      1  1.000000             1\n1   100      2  0.958333             1\n2   100      3  0.916667             1\n3   100      4  0.875000             1\n4   100      5  0.833333             1\n5   100      6  0.791667             1\n6   100      7  0.750000             1\n7   100      8  0.708333             1\n8   100      9  0.666667             0\n9   100     10  0.625000             0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event</th>\n      <th>place</th>\n      <th>score</th>\n      <th>all_american</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>2</td>\n      <td>0.958333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>3</td>\n      <td>0.916667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>4</td>\n      <td>0.875000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>5</td>\n      <td>0.833333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100</td>\n      <td>6</td>\n      <td>0.791667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100</td>\n      <td>7</td>\n      <td>0.750000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>8</td>\n      <td>0.708333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>9</td>\n      <td>0.666667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100</td>\n      <td>10</td>\n      <td>0.625000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"event\", \"place\", \"score\", \"all_american\"]].head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVC\n",
    "\n",
    "To start, we will compare the available kernels for SVM. Testing showed that the scaled dataset had better performance than either the feature reduced, plain, or sequentially selected dataset so we will be using that."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_on_event(x_type=\"scaled\", y_type=\"all_am\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM with linear kernel and default parameters\n",
      "\tf1 score: 0.543\n",
      "\tpercent positive: 0.6\n",
      "\tpercent correct all american 0.661\n",
      "\n",
      "SVM with poly kernel and default parameters\n",
      "\tf1 score: 0.542\n",
      "\tpercent positive: 0.513\n",
      "\tpercent correct all american 0.67\n",
      "\n",
      "SVM with rbf kernel and default parameters\n",
      "\tf1 score: 0.549\n",
      "\tpercent positive: 0.612\n",
      "\tpercent correct all american 0.598\n",
      "\n",
      "SVM with sigmoid kernel and default parameters\n",
      "\tf1 score: 0.387\n",
      "\tpercent positive: 0.484\n",
      "\tpercent correct all american 0.384\n"
     ]
    }
   ],
   "source": [
    "for kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "    print(f\"\\nSVM with {kernel} kernel and default parameters\")\n",
    "\n",
    "    svm = SVC(kernel=kernel, class_weight=\"balanced\", probability=True, random_state=0)\n",
    "    svm.fit(X_train, y_train)\n",
    "    preds = svm.predict(X_train)\n",
    "    prob_preds = svm.predict_proba(X_train)[:, 1] # Gives 0 then 1\n",
    "    print(f\"\\tf1 score: {round(f1_score(y_train, preds), 3)}\")\n",
    "    print(f\"\\tpercent positive: {round(np.mean(preds), 3)}\")\n",
    "    print(f\"\\tpercent correct all american {round(percent_all_american_score(None, prob_preds, X_train.index), 3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are interesting results here. Notably, sigmoid kernel performs by far the wost. Compared to logistic regression every other kernel is predicting too many positive examples but maintains a better accuracy for the all american selections. Of these, polynomial kernel seems to perform the best."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SVR\n",
    "Based on the observation that SVC predicts the probabilities well but not the classes well I am expecting SVR to perform better as it is better suited for continuous output. We will also be import two new metrics that better fit the regression problem. Note that because the score is on a scale of 1-24 we can roughly interpret the error as the difference in predicted place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_on_event(x_type=\"scaled\", y_type=\"score\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVR with linear kernel and default parameters\n",
      "\tMSE: 0.071 or roughly 1.704 places\n",
      "\tMAE: 0.22 or roughly 5.28 places\n",
      "\tpercent correct all american 0.587\n",
      "\n",
      "SVR with poly kernel and default parameters\n",
      "\tMSE: 0.069 or roughly 1.656 places\n",
      "\tMAE: 0.215 or roughly 5.16 places\n",
      "\tpercent correct all american 0.615\n",
      "\n",
      "SVR with rbf kernel and default parameters\n",
      "\tMSE: 0.07 or roughly 1.68 places\n",
      "\tMAE: 0.218 or roughly 5.232 places\n",
      "\tpercent correct all american 0.548\n",
      "\n",
      "SVR with sigmoid kernel and default parameters\n",
      "\tMSE: 28.47 or roughly 683.28 places\n",
      "\tMAE: 4.479 or roughly 107.496 places\n",
      "\tpercent correct all american 0.375\n"
     ]
    }
   ],
   "source": [
    "for kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "    print(f\"\\nSVR with {kernel} kernel and default parameters\")\n",
    "\n",
    "    svm = SVR(kernel=kernel)\n",
    "    svm.fit(X_train, y_train)\n",
    "    preds = svm.predict(X_train)\n",
    "\n",
    "    mse = round(mean_squared_error(y_train, preds), 3)\n",
    "    mae = round(mean_absolute_error(y_train, preds), 3)\n",
    "    print(f\"\\tMSE: {mse} or roughly {round(mse*24, 3)} places\")\n",
    "    print(f\"\\tMAE: {mae} or roughly {round(mae*24, 3)} places\")\n",
    "    print(f\"\\tpercent correct all american {round(percent_all_american_score(None, preds, X_train.index), 3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once again sigmoid kernel notably worse whereas the other are comparable with polynomial kernel doing slightly better. While the SVR gives us a more tangible result through the error the performance is not a marked improvement. If we take the best performing model of the polynomial kernel we can examine the visualize the output to see that a problem lies in the distribution of predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "svm = SVR(kernel=\"poly\")\n",
    "svm.fit(X_train, y_train)\n",
    "preds = svm.predict(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "# Plot actual distribution\n",
    "ax1.hist(y_train, bins=8, color=\"blue\", ec=\"black\")\n",
    "ax1.set_title(\"Actual scores\")\n",
    "ax1.set_xlabel(\"Score\")\n",
    "ax1.set_ylabel(\"Number of values\")\n",
    "\n",
    "ax2.hist(preds, bins=8, color=\"orange\", ec=\"black\")\n",
    "ax2.set_title(\"Predicted scores\")\n",
    "ax2.set_xlabel(\"Score\")\n",
    "ax2.set_ylabel(\"Number of values\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seeing that the intended distribution is perfectly normal and our model's output is clearly Guassian for my own interest I want to see if coercing the predictions into a normal distribution improves performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with polynomial kernel and uniform output\n",
      "\tMSE: 0.099 or roughly 2.376 places\n",
      "\tMAE: 0.243 or roughly 5.832 places\n",
      "\tpercent correct all american 0.615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import quantile_transform\n",
    "flattened = quantile_transform(np.array(preds).reshape(-1, 1), n_quantiles=len(preds), output_distribution=\"uniform\", random_state=0, copy=True)\n",
    "\n",
    "print(\"SVR with polynomial kernel and uniform output\")\n",
    "mse = round(mean_squared_error(y_train, flattened), 3)\n",
    "mae = round(mean_absolute_error(y_train, flattened), 3)\n",
    "print(f\"\\tMSE: {mse} or roughly {round(mse*24, 3)} places\")\n",
    "print(f\"\\tMAE: {mae} or roughly {round(mae*24, 3)} places\")\n",
    "print(f\"\\tpercent correct all american {round(percent_all_american_score(None, flattened, X_train.index), 3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ultimately, the performance is not any better than the original model output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM Conclusion\n",
    "\n",
    "While using support vector machines I tried both classification and regression. In both cases, the polynomial kernel performed best with default parameters. Additionally, the classification model performed better on my metric of ranking top eight athletes. While SVM is the best performing model of the three it still fails to beat the baseline of predicting using only one column.\n",
    "\n",
    "However, because SVM is the best performing model which also has a wealth of hyperparameters to tune it is the model I am choosing to optimize in part 4 of the project."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Throughout this report I tried spectral clustering, logistic regression, and support vector machines as models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}